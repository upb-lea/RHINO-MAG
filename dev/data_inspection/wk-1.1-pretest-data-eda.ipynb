{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9146be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from mc2.features.features_torch import Featurizer, MC2Loss\n",
    "from mc2.training.routine import evaluate_recursively\n",
    "from mc2.data_management import EXPERIMENT_LOGS_ROOT, NORMALIZATION_ROOT, load_hdf5_pretest_data\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3afed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multilevel_df(nested_dict):\n",
    "    \"\"\"Convert 3-level nested dict to DataFrame with outer keys as index and 2-level columns\"\"\"\n",
    "    dfs_by_model = []\n",
    "    for model_name, model_metrics in nested_dict.items():\n",
    "        # Create tuples for MultiIndex columns (scenario, metric)\n",
    "        tuples = [(scenario, metric) for scenario in model_metrics.keys() for metric in model_metrics[scenario].keys()]\n",
    "        values = [model_metrics[scenario][metric] for scenario in model_metrics.keys() for metric in model_metrics[scenario].keys()]\n",
    "        \n",
    "        # Create DataFrame for this model\n",
    "        df_model = pd.DataFrame([values], columns=pd.MultiIndex.from_tuples(tuples), index=[model_name])\n",
    "        dfs_by_model.append(df_model)\n",
    "    \n",
    "    # Concatenate and set column names\n",
    "    df = pd.concat(dfs_by_model, axis=0)\n",
    "    #df.columns.names = ['Scenario', 'Metric']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dfb941",
   "metadata": {},
   "source": [
    "# Test against pretest materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78c34fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# load up model\n",
    "guid_normal = {\n",
    "    \"3C90\": \"a2dc4ce1\",  # best test set score was 92.78 (A/m)²\n",
    "    \"N87\": \"93c403c2\",  # best test set score was 17.15 (A/m)²\n",
    "}\n",
    "# load up model with custom loss\n",
    "guid_custom_loss = {\"3C90\": \"09da6665\", \"N87\": \"51b88872\"}\n",
    "n_units = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e0fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper\n",
    "\n",
    "n_plots = 5\n",
    "scenario_labels = [\"10% unknown\", \"50% unknown\", \"90% unknown\"]\n",
    "\n",
    "def load_model_from_guid(mat, guid, fan_in, fan_out, device):\n",
    "    mdl = torch.nn.GRU(fan_in, fan_out, batch_first=True)\n",
    "    mdl.load_state_dict(torch.load(EXPERIMENT_LOGS_ROOT / f\"{mat}_{guid}\" / f\"{mat}_{guid}.pt\", map_location=device))\n",
    "    mdl = mdl.to(device)\n",
    "    return mdl\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate_pretest_scenarios(\n",
    "    mat, guid, evaluate_with_gru_cell: bool, show_plots: bool = False\n",
    "):\n",
    "    B, T, H_init, H_true, loss, loss_short, msks_scenarios_N_tup = load_hdf5_pretest_data(mat)\n",
    "    B.shape, T.shape, H_init.shape, H_true.shape\n",
    "    max_H = {\"3C90\":  1313.42,  # A/m for 3C90 (read from training log, TODO: save this somewhere else)\n",
    "         \"N87\":   321.14   # A/m for N87 (read from training log)\n",
    "        }[mat]\n",
    "    max_B = {\"3C90\": 0.51, \"N87\": 0.45}[mat]  # in T for 3C90 and N87 \n",
    "    max_T = 100  # degC\n",
    "    B_t = torch.tensor(B, device=device, dtype=torch.float32)\n",
    "    T_t = torch.tensor(T, device=device, dtype=torch.float32)\n",
    "\n",
    "    # prepare featurizer\n",
    "    featurizer = Featurizer(mat_lbl=mat, device=device)\n",
    "    # read norm constants\n",
    "    norm_consts_BP = pd.read_parquet(NORMALIZATION_ROOT / f\"{mat}_normalization_constants.parquet\")\n",
    "    featurizer.norm_consts_BP = torch.tensor(norm_consts_BP.to_numpy(), device=device, dtype=torch.float32)\n",
    "    featurizer.n_inputs = featurizer.norm_consts_BP.shape[1]\n",
    "\n",
    "    # load model\n",
    "    mdl = load_model_from_guid(mat, guid, featurizer.n_inputs, n_units, device)\n",
    "\n",
    "    H_true_t = torch.tensor(H_true, device=device, dtype=torch.float32)\n",
    "    if evaluate_with_gru_cell:\n",
    "        # rebuild GRU into GRUcell\n",
    "        gru_cell = torch.nn.GRUCell(featurizer.n_inputs, n_units)\n",
    "\n",
    "        def replace_key(d):\n",
    "            replacement_map_d = {\n",
    "                \"weight_ih_l0\": \"weight_ih\",\n",
    "                \"weight_hh_l0\": \"weight_hh\",\n",
    "                \"bias_ih_l0\": \"bias_ih\",\n",
    "                \"bias_hh_l0\": \"bias_hh\",\n",
    "            }\n",
    "            return {replacement_map_d.get(k, k): v for k, v in d.items()}\n",
    "\n",
    "        gru_cell.load_state_dict(replace_key(mdl.state_dict()))\n",
    "        gru_cell = gru_cell.to(device)\n",
    "        mdl_eval = gru_cell\n",
    "        arch_lbl = \"gru_cell\"\n",
    "    else:\n",
    "        mdl_eval = mdl\n",
    "        arch_lbl = \"gru\"\n",
    "    H_init_t_MX = None\n",
    "    print(f\"Using architecture: {arch_lbl}\")\n",
    "    metrics_d = {}\n",
    "    for scenario_i, msk_N in enumerate(msks_scenarios_N_tup):\n",
    "        print(f\"  Scenario {scenario_i} - {scenario_labels[scenario_i]}: \")\n",
    "        if evaluate_with_gru_cell:\n",
    "            H_init_t_MX = (\n",
    "                torch.tensor(H_init[msk_N][: , ~np.any(np.isnan(H_init[msk_N]), axis=0)], device=device, dtype=torch.float32)\n",
    "                / max_H\n",
    "            )\n",
    "        warm_up_len = H_init.shape[1] - np.isnan(H_init[msk_N][0]).astype(int).sum()\n",
    "        B_scenario = B_t[msk_N] / max_B\n",
    "        T_scenario = T_t[msk_N] / max_T\n",
    "        H_true_scenario = H_true_t[msk_N] / max_H\n",
    "        pretest_tensors_d = {\"pretest\": {\"model_in_AS_l\": [(B_scenario, T_scenario)], \"H\": [H_true_scenario]}}\n",
    "        \n",
    "\n",
    "        _, preds_MS_l = evaluate_recursively(\n",
    "            mdl_eval,\n",
    "            tensors_d=pretest_tensors_d,\n",
    "            loss_fn=MC2Loss(),\n",
    "            featurizer=featurizer,\n",
    "            max_H=max_H,\n",
    "            n_states=n_units,\n",
    "            set_lbl=\"pretest\",\n",
    "            warm_up_phase_target_MX=H_init_t_MX,\n",
    "            model_arch='gru_cell' if evaluate_with_gru_cell else 'gru',\n",
    "        )\n",
    "        preds = preds_MS_l[0].cpu().numpy()[:, warm_up_len:]\n",
    "        H_gt_full = H_true_t.cpu().numpy()[msk_N]\n",
    "        H_gt = H_gt_full[:, warm_up_len:]\n",
    "\n",
    "        # calculate metrics\n",
    "        wce_per_sequence_M = np.max(np.abs(preds - H_gt), axis=1)\n",
    "        mse_per_sequence_M = np.mean((preds - H_gt) ** 2, axis=1)\n",
    "        mse = np.mean(mse_per_sequence_M)\n",
    "        wce = np.max(np.abs(H_gt - preds))\n",
    "        sre_per_sequence = np.sqrt(mse_per_sequence_M) / np.sqrt(np.mean(H_gt**2, axis=1))  # sequence relative error\n",
    "        sre_avg = np.mean(sre_per_sequence)\n",
    "        sre_95th = np.percentile(sre_per_sequence, 95)\n",
    "        dbdt_full = np.gradient(B[msk_N], axis=1)\n",
    "        dbdt = dbdt_full[:, warm_up_len:]\n",
    "        #print(f\"DEBUG: {(dbdt*H_gt).sum(axis=1)=}\\n{(dbdt_full*H_gt_full).sum(axis=1)=}\\n{loss_short[msk_N].ravel()=}\\n{loss[msk_N].ravel()=}\")\n",
    "        nere_per_sequence = (((dbdt * preds) - (dbdt*H_gt)).sum(axis=1))  / np.abs(loss[msk_N])# normalized energy relative error\n",
    "        nere_avg = np.mean(nere_per_sequence)\n",
    "        nere_95th = np.percentile(nere_per_sequence, 95)\n",
    "        idx_argmax = np.argpartition(wce_per_sequence_M, -n_plots)[-n_plots:]  # worst case trajectories\n",
    "        print(f\"\\tMSE : {mse:>7.2f} (A/m)²\")\n",
    "        #print(f\"\\tRMSE: {np.sqrt(mse):>7.2f} A/m\")\n",
    "        print(f\"\\tWCE : {wce:>7.2f} A/m\")\n",
    "\n",
    "\n",
    "        metrics_d[scenario_labels[scenario_i]] = {\n",
    "            \"mse\": np.round(mse, 3).item(),\n",
    "            \"wce\": np.round(wce, 3).item(),\n",
    "            \"sre_avg\": np.round(sre_avg, 3).item(),\n",
    "            \"sre_95th\": np.round(sre_95th, 3).item(),\n",
    "            \"nere_avg\": np.round(nere_avg, 3).item(),\n",
    "            \"nere_95th\": np.round(nere_95th, 3).item(),\n",
    "        }\n",
    "\n",
    "        # as long as the model can only take the first gt value as initialization, all scenarios\n",
    "        #  will be the same. The trajectories are the same among the scenarios.\n",
    "\n",
    "        # Differences in loss occur due to the different frame being observed for rating\n",
    "        if show_plots:\n",
    "            fig, axes = plt.subplots(n_plots, 1, sharex=True, sharey=\"col\", figsize=(10, 2.5 * n_plots))\n",
    "            for tst_i in range(n_plots):\n",
    "                tst_idx = idx_argmax[tst_i]\n",
    "                ax = axes[tst_i]\n",
    "                ax.plot(H_gt[tst_idx], label=\"gt\")\n",
    "                ax.plot(preds[tst_idx], label=\"pred\", ls=\"dashed\")\n",
    "                ax.annotate(\n",
    "                    f\"MSE {mse_per_sequence_M[tst_idx]:.1f} (A/m)² | WCE {wce_per_sequence_M[tst_idx]:.1f} A/m\", \n",
    "                    (0.3, 0.1), xycoords=ax.transAxes\n",
    "                )\n",
    "\n",
    "            axes[0].set_title(f\"Worst-case predictions for {mat} - {scenario_labels[scenario_i]}\")\n",
    "            axes.flatten()[0].legend()\n",
    "            for ax in axes.flatten():\n",
    "                ax.grid(alpha=0.3)\n",
    "            for ax in axes:\n",
    "                ax.set_ylabel(\"H in A/m\")\n",
    "\n",
    "            for ax in [axes[-1]]:\n",
    "                ax.set_xlabel(\"Sequence step\")\n",
    "            fig.tight_layout()\n",
    "    return metrics_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81f7617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_pretest_evaluation_dict(mat):\n",
    "      \n",
    "    metrics_gru_cell_custom_loss = evaluate_pretest_scenarios(mat, guid_custom_loss[mat], True, show_plots=False)\n",
    "    print()\n",
    "    metrics_gru_cell = evaluate_pretest_scenarios(mat, guid_normal[mat], False, show_plots=False)\n",
    "    hosts_d = {\"3C90\": {scenario_labels[0]: {\"mse\": None, \"wce\": None, \"sre_avg\": 0.1305, \"sre_95th\": 0.347, \"nere_avg\": 0.007623, \"nere_95th\": 0.01928}, # 90 % known\n",
    "            scenario_labels[1]: {\"mse\": None, \"wce\": None, \"sre_avg\": 0.1602, \"sre_95th\": 0.3443, \"nere_avg\": 0.0341, \"nere_95th\": 0.05603}, # 50 % known\n",
    "            scenario_labels[2]: {\"mse\": None, \"wce\": None, \"sre_avg\": 0.1704, \"sre_95th\": 0.3476, \"nere_avg\": 0.0618, \"nere_95th\": 0.07476}}, # 10 % known\n",
    "            \"N87\": {scenario_labels[0]: {\"mse\": None, \"wce\": None, \"sre_avg\": 0.1962, \"sre_95th\": 0.521, \"nere_avg\": 0.007805, \"nere_95th\": 0.0157}, # 90 % known\n",
    "            scenario_labels[1]: {\"mse\": None, \"wce\": None, \"sre_avg\": 0.2767, \"sre_95th\": 0.8498, \"nere_avg\": 0.02577, \"nere_95th\": 0.05509}, # 50 % known\n",
    "            scenario_labels[2]: {\"mse\": None, \"wce\": None, \"sre_avg\": 0.3028, \"sre_95th\": 0.9999, \"nere_avg\": 0.04828, \"nere_95th\": 0.0681} # 10 % known\n",
    "            }}\n",
    "    all_models_d = {\"hosts\": hosts_d[mat], \"gru_cell\": metrics_gru_cell, \"gru_cell_CL\": metrics_gru_cell_custom_loss, }\n",
    "    return all_models_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbf1fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N87\n",
    "df_models_N87 = create_multilevel_df(prepare_pretest_evaluation_dict(\"N87\"))\n",
    "display(HTML(df_models_N87.T.to_html(float_format=\"%.3f\", bold_rows=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f8c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3C90\n",
    "df_models_3C90 = create_multilevel_df(prepare_pretest_evaluation_dict(\"3C90\"))\n",
    "display(HTML(df_models_3C90.T.to_html(float_format=\"%.3f\", bold_rows=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f1bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(pd.concat([df_models_N87.T, df_models_3C90.T], axis=1, keys=[\"N87\", \"3C90\"]).to_html(float_format=\"%.3f\", bold_rows=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c16c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "class HostNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HostNet, self).__init__()\n",
    "\n",
    "        self.lstm_B = nn.LSTM(1, 6, num_layers=1, batch_first=True, bidirectional=False)\n",
    "\n",
    "        self.lstm_H = nn.LSTM(1, 6, num_layers=1, batch_first=True, bidirectional=False)\n",
    "\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(6 *2 + 2 , 6 *2 + 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(6 *2 + 2, 8),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(8 , 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_B: Tensor, seq_H: Tensor, scal: Tensor, T: Tensor, device) -> Tensor:\n",
    "\n",
    "        seq_B = seq_B.float()\n",
    "        seq_H = seq_H.float()\n",
    "        scal = scal.float()\n",
    "        T = T.float()\n",
    "\n",
    "        x_B, _ = self.lstm_B(seq_B)\n",
    "        x_B = x_B[:, -1, :]\n",
    "\n",
    "        x_H, _ = self.lstm_H(seq_H)\n",
    "        x_H = x_H[:, -1, :]\n",
    "\n",
    "\n",
    "        output = self.projector(torch.cat((scal, T, x_B, x_H), dim=1))\n",
    "        output = output.to(device)\n",
    "\n",
    "        return output\n",
    "    \n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(HostNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca67fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(mdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45350a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.gradient(B, axis=1).shape, np.diff(B, axis=1).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
