{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0949e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93a8a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from mc2.data_management import EXPERIMENT_LOGS_ROOT,MODEL_DUMP_ROOT\n",
    "from mc2.models.jiles_atherton import JilesAthertonStatic, JilesAthertonWithGRU, JilesAthertonGRU, JilesAthertonStatic2\n",
    "from mc2.models.RNN import GRU\n",
    "from mc2.models.model_interface import JAwGRUwInterface, JAGRUwInterface, load_model, RNNwInterface, JAwInterface\n",
    "import jax\n",
    "import equinox as eqx\n",
    "import json\n",
    "import pathlib\n",
    "from typing import Type\n",
    "from mc2.models.model_interface import ModelInterface\n",
    "from mc2.runners.model_setup_jax import get_normalizer\n",
    "import jax.numpy as jnp\n",
    "from mc2.data_management import EXPERIMENT_LOGS_ROOT, NORMALIZATION_ROOT, load_hdf5_pretest_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e6ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = \"f57e0626\"\n",
    "seed = 1\n",
    "def load_preds_n_gt(exp_id, seed):\n",
    "    fp = EXPERIMENT_LOGS_ROOT / f\"exp_{exp_id}_seed_{seed}_preds_transformed.parquet\"\n",
    "    fp2 = EXPERIMENT_LOGS_ROOT / f\"exp_{exp_id}_seed_{seed}_gt_transformed.parquet\"\n",
    "    fp3 = EXPERIMENT_LOGS_ROOT / f\"exp_{exp_id}_seed_{seed}_preds_untransformed.parquet\"\n",
    "    fp4 = EXPERIMENT_LOGS_ROOT / f\"exp_{exp_id}_seed_{seed}_gt.parquet\"\n",
    "    preds_transformed_MS = pd.read_parquet(fp).to_numpy()\n",
    "    preds_untransformed_MS = pd.read_parquet(fp3).to_numpy()\n",
    "    gt_transformed_MS = pd.read_parquet(fp2).to_numpy()\n",
    "    gt_MS = pd.read_parquet(fp4).to_numpy()\n",
    "    return gt_MS, gt_transformed_MS, preds_transformed_MS, preds_untransformed_MS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3889fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_worst_predictions3(exp_id, seed, freq_idx, metric=\"MSE\"):\n",
    "    gt_MS,pred_MS = load_preds_n_gt2(exp_id, seed, freq_idx)\n",
    "    \n",
    "    mae_M = np.mean(np.abs(gt_MS - pred_MS), axis=-1)\n",
    "    mse_M = np.mean((gt_MS - pred_MS)**2, axis=-1)\n",
    "    rmse_M = np.sqrt(np.mean((gt_MS - pred_MS)**2, axis=-1))/np.sqrt(np.mean(gt_MS**2, axis=-1))\n",
    "    if metric==\"RMSE\":\n",
    "        sorted_idx = np.argsort(rmse_M)[::-1]\n",
    "    elif metric==\"MAE\":\n",
    "        sorted_idx = np.argsort(mae_M)[::-1]\n",
    "    else:   \n",
    "        sorted_idx = np.argsort(mse_M)[::-1]\n",
    "    worst_idx=sorted_idx[:5]\n",
    "    \n",
    "    print(f\"MAE {mae_M.mean():.1f} A/m | MSE {mse_M.mean():.1f} (A/m)² | RMSE {rmse_M.mean():.3f}\")\n",
    "\n",
    "    fig, axes = plt.subplots(5, 1 , sharex=True, sharey=\"col\", figsize=(10, 15))\n",
    "    axes[0].set_title(f\"Worst {metric}\")\n",
    "    for i,idx in enumerate(worst_idx):\n",
    "        ax = axes[i]\n",
    "        ax.plot(gt_MS[idx], label='gt')\n",
    "        ax.plot(pred_MS[idx], label='pred', ls='dashed')\n",
    "        ax.annotate(f\"MAE {mae_M[idx]:.1f} A/m | \"\n",
    "                    f\"MSE {mse_M[idx]:.1f} (A/m)² | RMSE {rmse_M[idx]:.3f}\", \n",
    "                    (0.3, 0.1), xycoords=ax.transAxes)\n",
    "            \n",
    "    axes.flatten()[0].legend()\n",
    "    for ax in axes.flatten():\n",
    "        ax.grid(alpha=0.3)\n",
    "    for ax in axes:\n",
    "        ax.set_ylabel(\"H in A/m\")\n",
    "    for ax in [axes[-1]]:\n",
    "        ax.set_xlabel(\"Sequence step\")\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f7096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_first_predictions(exp_key, show_normalized_pred=False):\n",
    "    gt_MS, gt_transformed_MS, preds_transformed_MS, preds_untransformed_MS = load_preds_n_gt(**experiments_d[exp_key])\n",
    "    fig, axes = plt.subplots(5, 1 + int(show_normalized_pred), sharex=True, sharey=\"col\", figsize=(10, 15))\n",
    "    mae_M = np.mean(np.abs(gt_MS - preds_untransformed_MS), axis=-1)\n",
    "    mse_M = np.mean((gt_MS - preds_untransformed_MS)**2, axis=-1)\n",
    "    print(f\"MAE {mae_M.mean():.1f} A/m | MSE {mse_M.mean():.1f} (A/m)²\")\n",
    "    for tst_idx in range(axes.shape[0]):\n",
    "        if show_normalized_pred:\n",
    "            ax = axes[tst_idx, 0]\n",
    "        else:\n",
    "            ax = axes[tst_idx]\n",
    "        ax.plot(gt_MS[tst_idx], label='gt')\n",
    "        ax.plot(preds_untransformed_MS[tst_idx], label='pred', ls='dashed')\n",
    "        ax.annotate(f\"MAE {mae_M[tst_idx]:.1f} A/m | \"\n",
    "                    f\"MSE {mse_M[tst_idx]:.1f} (A/m)²\",\n",
    "                    (0.3, 0.1), xycoords=ax.transAxes)\n",
    "        if show_normalized_pred:\n",
    "            axes[tst_idx, 1].plot(gt_transformed_MS[tst_idx])\n",
    "            axes[tst_idx, 1].plot(preds_transformed_MS[tst_idx], ls='dashed')\n",
    "            \n",
    "    axes.flatten()[0].legend()\n",
    "    for ax in axes.flatten():\n",
    "        ax.grid(alpha=0.3)\n",
    "    for ax in axes[:, 0] if show_normalized_pred else axes:\n",
    "        ax.set_ylabel(\"H in A/m\")\n",
    "    if show_normalized_pred:\n",
    "        for ax in axes[:, 1]:\n",
    "            ax.set_ylabel(\"H normalized\")\n",
    "    for ax in axes[-1, :] if show_normalized_pred else [axes[-1]]:\n",
    "        ax.set_xlabel(\"Sequence step\")\n",
    "    fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de983a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preds_n_gt2(exp_id, seed, freq_idx):\n",
    "    gt = EXPERIMENT_LOGS_ROOT / f\"{exp_id}/seed_{seed}_seq_{freq_idx}_gt.parquet\"\n",
    "    pred = EXPERIMENT_LOGS_ROOT / f\"{exp_id}/seed_{seed}_seq_{freq_idx}_preds.parquet\"\n",
    "    gt_MS = pd.read_parquet(gt).to_numpy()\n",
    "    pred_MS = pd.read_parquet(pred).to_numpy()\n",
    "    return gt_MS, pred_MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa29939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_test_mse_mae(exp_id, seed):\n",
    "    mses=[]\n",
    "    maes=[]\n",
    "    for idx in range(7):\n",
    "        gt = EXPERIMENT_LOGS_ROOT / f\"{exp_id}/seed_{seed}_seq_{idx}_gt.parquet\"\n",
    "        pred = EXPERIMENT_LOGS_ROOT / f\"{exp_id}/seed_{seed}_seq_{idx}_preds.parquet\"\n",
    "        gt_MS = pd.read_parquet(gt).to_numpy()\n",
    "        pred_MS = pd.read_parquet(pred).to_numpy()\n",
    "        mse_M = np.mean((gt_MS - pred_MS)**2)\n",
    "        mae_M = np.mean(np.abs(gt_MS - pred_MS))\n",
    "        mses.append(mse_M)\n",
    "        maes.append(mae_M)\n",
    "    return mses,maes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112a8149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_first_predictions2(exp_id, seed, freq_idx):\n",
    "    gt_MS,pred_MS = load_preds_n_gt2(exp_id, seed, freq_idx)\n",
    "    fig, axes = plt.subplots(5, 1 , sharex=True, sharey=\"col\", figsize=(10, 15))\n",
    "    mae_M = np.mean(np.abs(gt_MS - pred_MS), axis=-1)\n",
    "    mse_M = np.mean((gt_MS - pred_MS)**2, axis=-1)\n",
    "    print(f\"MAE {mae_M.mean():.1f} A/m | MSE {mse_M.mean():.1f} (A/m)²\")\n",
    "    for tst_idx in range(axes.shape[0]):\n",
    "        ax = axes[tst_idx]\n",
    "        ax.plot(gt_MS[tst_idx], label='gt')\n",
    "        ax.plot(pred_MS[tst_idx], label='pred', ls='dashed')\n",
    "        ax.annotate(f\"MAE {mae_M[tst_idx]:.1f} A/m | \"\n",
    "                    f\"MSE {mse_M[tst_idx]:.1f} (A/m)²\",\n",
    "                    (0.3, 0.1), xycoords=ax.transAxes)\n",
    "            \n",
    "    axes.flatten()[0].legend()\n",
    "    for ax in axes.flatten():\n",
    "        ax.grid(alpha=0.3)\n",
    "    for ax in axes:\n",
    "        ax.set_ylabel(\"H in A/m\")\n",
    "    for ax in [axes[-1]]:\n",
    "        ax.set_xlabel(\"Sequence step\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ccc375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_worst_predictions2(exp_id, seed, freq_idx):\n",
    "    gt_MS,pred_MS = load_preds_n_gt2(exp_id, seed, freq_idx)\n",
    "    \n",
    "    mae_M = np.mean(np.abs(gt_MS - pred_MS), axis=-1)\n",
    "    mse_M = np.mean((gt_MS - pred_MS)**2, axis=-1)\n",
    "    sorted_idx = np.argsort(mse_M)[::-1]\n",
    "    worst_mse=sorted_idx[:5]\n",
    "    sorted_idx = np.argsort(mae_M)[::-1]\n",
    "    worst_mae=sorted_idx[:5]\n",
    "    print(f\"MAE {mae_M.mean():.1f} A/m | MSE {mse_M.mean():.1f} (A/m)²\")\n",
    "\n",
    "    for metric in [\"MSE\",\"MAE\"]:\n",
    "        worst_idx = worst_mse if metric==\"MSE\" else worst_mae\n",
    "        fig, axes = plt.subplots(5, 1 , sharex=True, sharey=\"col\", figsize=(10, 15))\n",
    "        axes[0].set_title(f\"Worst {metric}\")\n",
    "        for i,idx in enumerate(worst_idx):\n",
    "            ax = axes[i]\n",
    "            ax.plot(gt_MS[idx], label='gt')\n",
    "            ax.plot(pred_MS[idx], label='pred', ls='dashed')\n",
    "            ax.annotate(f\"MAE {mae_M[idx]:.1f} A/m | \"\n",
    "                        f\"MSE {mse_M[idx]:.1f} (A/m)²\",\n",
    "                        (0.3, 0.1), xycoords=ax.transAxes)\n",
    "                \n",
    "        axes.flatten()[0].legend()\n",
    "        for ax in axes.flatten():\n",
    "            ax.grid(alpha=0.3)\n",
    "        for ax in axes:\n",
    "            ax.set_ylabel(\"H in A/m\")\n",
    "        for ax in [axes[-1]]:\n",
    "            ax.set_xlabel(\"Sequence step\")\n",
    "\n",
    "        fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46346e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_test_mse_rmse(exp_id, seed):\n",
    "    mses=[]\n",
    "    rmse=[]\n",
    "    for idx in range(7):\n",
    "        gt = EXPERIMENT_LOGS_ROOT / f\"{exp_id}/seed_{seed}_seq_{idx}_gt.parquet\"\n",
    "        pred = EXPERIMENT_LOGS_ROOT / f\"{exp_id}/seed_{seed}_seq_{idx}_preds.parquet\"\n",
    "        gt_MS = pd.read_parquet(gt).to_numpy()\n",
    "        pred_MS = pd.read_parquet(pred).to_numpy()\n",
    "        mse_per_sequence_M = np.mean((pred_MS - gt_MS) ** 2, axis=1)\n",
    "        mse_M = np.mean(mse_per_sequence_M)\n",
    "        sre_per_sequence = np.sqrt(mse_per_sequence_M) / np.sqrt(np.mean(gt_MS**2, axis=1))\n",
    "        rmse_M = np.mean(sre_per_sequence)\n",
    "        mses.append(mse_M)\n",
    "        rmse.append(rmse_M)\n",
    "    return mses,rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9955ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_id = \"3C90_8c804f77\"#\"3C90_78f120d2\"\n",
    "#exp_id =\"3C90_7632996d-4c4c-40\"#(RMS-GRU8)#\"3C90_4d5b2cc1-4e08-46\"#\"3C90_5cf07234-fbc2-44\" #(RMS-JA+GRu 10epoche) # ##(MSE-GRU8)#\n",
    "#exp_id = \"3C90_b8d1fe17-2f6f-40\" #(JA-100)\n",
    "#exp_id = \"3C90_0a78ff01-c96b-4d\" #(JA-WITH-GRU8-100)\n",
    "#exp_id = \"3C90_a309167c-3e73-40\" #(GRU8-150)\n",
    "#exp_id = \"3C90_1c1af93c-e010-4a\" #(JAGRU-100)\n",
    "#exp_id = \"3C90_e7266ae8-99a8-42\" #(JA2-25)\n",
    "#exp_id = \"3C90_c78a3d43-ce9e-46\" #(JAGRUlin-100)\n",
    "#exp_id = \"3C90_a4e69149-1e9f-4d\" #(JA2-100)\n",
    "\n",
    "#exp_id = \"3C90_b908af2d-7a65-41\"# (GRU8-500-new2)\n",
    "#exp_id = \"3C90_4ec8f810-298b-49\"# (JA-150-new2)\n",
    "exp_id = \"3C90_cf80a118-8ef2-45\" #(JAGRU-500-new2)\n",
    "seed = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_trend = EXPERIMENT_LOGS_ROOT / f\"{exp_id}/seed_{seed}_loss_trends.parquet\"\n",
    "loss_train_val = pd.read_parquet(loss_trend).to_numpy()\n",
    "\n",
    "epochs = np.arange(1, len(loss_train_val) + 1)\n",
    "train_loss = loss_train_val[:, 0]\n",
    "val_loss = loss_train_val[:, 1]\n",
    "\n",
    "# Figure mit zwei Subplots\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n",
    "\n",
    "# Training Loss Plot\n",
    "axes[0].plot(epochs, train_loss, color=\"tab:blue\", marker=\"o\", label=\"Training Loss (normalized)\")\n",
    "axes[0].set_ylabel(\"Training Loss\", color=\"tab:blue\")\n",
    "axes[0].tick_params(axis=\"y\", labelcolor=\"tab:blue\")\n",
    "axes[0].legend(loc=\"upper right\")\n",
    "axes[0].set_title(\"Training Loss\")\n",
    "axes[0].set_yscale(\"log\")\n",
    "\n",
    "# Validation Loss Plot\n",
    "axes[1].plot(epochs, val_loss, color=\"tab:red\", marker=\"s\", label=\"Validation (non-normalized)\")\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Validation\", color=\"tab:red\")\n",
    "axes[1].tick_params(axis=\"y\", labelcolor=\"tab:red\")\n",
    "axes[1].legend(loc=\"upper right\")\n",
    "axes[1].set_title(\"Validation Loss\")\n",
    "axes[1].set_yscale(\"log\")\n",
    "# Layout und Anzeige\n",
    "fig.suptitle(\"Training vs Validation Loss\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1eb198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mc2.features.features_jax import compute_fe_single\n",
    "def featurize(norm_B_past, norm_H_past, norm_B_future, temperature):\n",
    "        past_length = norm_B_past.shape[0]\n",
    "        future_length = norm_B_future.shape[0]\n",
    "\n",
    "        featurized_B = compute_fe_single(jnp.hstack([norm_B_past, norm_B_future]), n_s=10)\n",
    "\n",
    "        return featurized_B[past_length:]\n",
    "\n",
    "normalizer, data_tuple = get_normalizer(\n",
    "    \"3C90\",\n",
    "    featurize,\n",
    "    1,\n",
    "    True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c309b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "JilesAthertonGRU_part = partial(JilesAthertonGRU, normalizer=normalizer)\n",
    "\n",
    "loaded_model=load_model(MODEL_DUMP_ROOT/f\"{exp_id[5:]}.eqx\",JilesAthertonWithGRU) # GRU ,JilesAthertonStatic,JilesAthertonGRU_part\n",
    "wrappend_model = JAwGRUwInterface(loaded_model, normalizer,featurize) #RNNwInterface, JAwInterface,JAGRUwInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e462a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "training_data_path = EXPERIMENT_LOGS_ROOT /\"jax_experiments\"/ f\"{exp_id [5:]}.json\"\n",
    "with open(training_data_path, \"r\") as f:\n",
    "    training_and_test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32d1521",
   "metadata": {},
   "outputs": [],
   "source": [
    "mses,rmses = freq_test_mse_rmse(exp_id, seed)\n",
    "print(\"Total:\", f\"RMSE {np.mean(rmses):.3f} A/m | MSE {np.mean(mses).mean():.1f} (A/m)²\", \"\\n\")\n",
    "for i,(val_mse,val_rmse) in enumerate(zip(mses,rmses)):\n",
    "    print(f\"Freq_idx {i}: \",f\"RMSE {(val_rmse):.3f} A/m | MSE {(val_mse).mean():.1f} (A/m)²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500cb0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_worst_predictions3(exp_id, seed,2, metric=\"RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9fcd2b",
   "metadata": {},
   "source": [
    "## Pretest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02f0c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mc2.features.features_jax import compute_fe_single\n",
    "def featurize(norm_B_past, norm_H_past, norm_B_future, temperature):\n",
    "        past_length = norm_B_past.shape[0]\n",
    "        future_length = norm_B_future.shape[0]\n",
    "\n",
    "        featurized_B = compute_fe_single(jnp.hstack([norm_B_past, norm_B_future]), n_s=10)\n",
    "\n",
    "        return featurized_B[past_length:]\n",
    "\n",
    "normalizer, data_tuple = get_normalizer(\n",
    "    \"3C90\",\n",
    "    featurize,\n",
    "    1,\n",
    "    True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c12ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "#exp_id = \"3C90_8c804f77\"#\"3C90_78f120d2\"\n",
    "#exp_id =\"3C90_7632996d-4c4c-40\"#(RMS-GRU8)#\"3C90_4d5b2cc1-4e08-46\"#\"3C90_5cf07234-fbc2-44\" #(RMS-JA+GRu 10epoche) # ##(MSE-GRU8)#\n",
    "#exp_id_ja = \"3C90_b8d1fe17-2f6f-40\" #(JA-100)\n",
    "#exp_id = \"3C90_0a78ff01-c96b-4d\" #(JA-WITH-GRU8-100)\n",
    "exp_id_gru = \"3C90_b908af2d-7a65-41\" #(GRU8-150)\n",
    "#exp_id = \"3C90_1c1af93c-e010-4a\" #(JAGRU-100)\n",
    "#exp_id = \"3C90_e7266ae8-99a8-42\" #(JA2-25)\n",
    "#exp_id_jagru = \"3C90_c78a3d43-ce9e-46\" #(JAGRUlin-100)\n",
    "#exp_id_ja2 = \"3C90_a4e69149-1e9f-4d\" #(JA2-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "#JilesAthertonGRU_part = partial(JilesAthertonGRU, normalizer=normalizer)\n",
    "# loaded_model=load_model(MODEL_DUMP_ROOT/f\"{exp_id_jagru[5:]}.eqx\",JilesAthertonGRU_part) # GRU ,JilesAthertonStatic,JilesAthertonGRU_part\n",
    "# wrappend_model_ja_gru = JAGRUwInterface(loaded_model, normalizer,featurize) #RNNwInterface, JAwInterface,JAGRUwInterface\n",
    "\n",
    "loaded_model=load_model(MODEL_DUMP_ROOT/f\"{exp_id_gru[5:]}.eqx\",GRU) # GRU ,JilesAthertonStatic,JilesAthertonGRU_part\n",
    "wrappend_model_gru = RNNwInterface(loaded_model, normalizer,featurize) #RNNwInterface, JAwInterface,JAGRUwInterface\n",
    "\n",
    "# loaded_model=load_model(MODEL_DUMP_ROOT/f\"{exp_id_ja[5:]}.eqx\",JilesAthertonStatic) # GRU ,JilesAthertonStatic,JilesAthertonGRU_part\n",
    "# wrappend_model_ja = JAwInterface(loaded_model, normalizer,featurize) #RNNwInterface, JAwInterface,JAGRUwInterface\n",
    "\n",
    "\n",
    "# loaded_model=load_model(MODEL_DUMP_ROOT/f\"{exp_id_ja2[5:]}.eqx\",JilesAthertonStatic2) # GRU ,JilesAthertonStatic,JilesAthertonGRU_part\n",
    "# wrappend_model_ja2 = JAwInterface(loaded_model, normalizer,featurize) #RNNwInterface, JAwInterface,JAGRUwInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac779f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jagru = JilesAthertonGRU(hidden_size=8,normalizer=normalizer,in_size=7,key=jax.random.PRNGKey(123))\n",
    "# wrappend_model_ja_gru = JAGRUwInterface(jagru, normalizer,featurize)\n",
    "\n",
    "# ja = JilesAthertonStatic(key=jax.random.PRNGKey(123))\n",
    "# wrappend_model_ja = JAwInterface(ja, normalizer,featurize)\n",
    "\n",
    "jaWgru = JilesAthertonWithGRU(hidden_size=8,in_size=7,key=jax.random.PRNGKey(123))\n",
    "wrappend_model_ja_gru = JAwGRUwInterface(jaWgru, normalizer,featurize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce505b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "def create_multilevel_df(nested_dict):\n",
    "    \"\"\"Convert 3-level nested dict to DataFrame with outer keys as index and 2-level columns\"\"\"\n",
    "    dfs_by_model = []\n",
    "    for model_name, model_metrics in nested_dict.items():\n",
    "        # Create tuples for MultiIndex columns (scenario, metric)\n",
    "        tuples = [(scenario, metric) for scenario in model_metrics.keys() for metric in model_metrics[scenario].keys()]\n",
    "        values = [model_metrics[scenario][metric] for scenario in model_metrics.keys() for metric in model_metrics[scenario].keys()]\n",
    "        \n",
    "        # Create DataFrame for this model\n",
    "        df_model = pd.DataFrame([values], columns=pd.MultiIndex.from_tuples(tuples), index=[model_name])\n",
    "        dfs_by_model.append(df_model)\n",
    "    \n",
    "    # Concatenate and set column names\n",
    "    df = pd.concat(dfs_by_model, axis=0)\n",
    "    #df.columns.names = ['Scenario', 'Metric']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb1825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = \"3C90\"\n",
    "B, T, H_init, H_true, loss, loss_short, msks_scenarios_N_tup = load_hdf5_pretest_data(mat)\n",
    "B.shape, T.shape, H_init.shape, H_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51fd728",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_labels = [\"10% unknown\", \"50% unknown\", \"90% unknown\"]\n",
    "\n",
    "def evaluate_pretest_scenarios_custom(\n",
    "    model_all, B, T, H_init, H_true, loss, msks_scenarios_N_tup, show_plots: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluates the given model on pretest scenarios with different amounts of unknown samples.\n",
    "    Works with batched NumPy inputs (model_all takes arrays of shape (batch, time)).\n",
    "    \"\"\"\n",
    "\n",
    "    metrics_d = {}\n",
    "\n",
    "    for scenario_i, msk_N in enumerate(msks_scenarios_N_tup):\n",
    "        print(f\"  Scenario {scenario_i} - {scenario_labels[scenario_i]}: \")\n",
    "\n",
    "        B_scenario = B[msk_N]\n",
    "        T_scenario = T[msk_N]\n",
    "        H_init_scenario = H_init[msk_N]\n",
    "        H_true_scenario = H_true[msk_N]\n",
    "\n",
    "        warm_up_len = np.sum(~np.isnan(H_init_scenario[0]))\n",
    "        print(warm_up_len/B_scenario.shape[1])\n",
    "        print(f\"    -> warm_up_len = {warm_up_len}\")\n",
    "\n",
    "\n",
    "        B_past = B_scenario[:, :warm_up_len]\n",
    "        H_past = H_init_scenario[:, :warm_up_len]\n",
    "        B_future = B_scenario[:, warm_up_len:]\n",
    "        T_batch = T_scenario.reshape(-1) \n",
    "\n",
    "        # preds = model_all(\n",
    "        #     B_past=B_past,\n",
    "        #     H_past=H_past,\n",
    "        #     B_future=B_future,\n",
    "        #     T=T_batch,\n",
    "        # ) \n",
    "        preds = model_all.call_with_warmup(\n",
    "            B_past=B_past,\n",
    "            H_past=H_past,\n",
    "            B_future=B_future,\n",
    "            T=T_batch,\n",
    "        ) \n",
    "\n",
    "        H_gt = H_true_scenario[:, warm_up_len:]\n",
    "\n",
    "        # ---- metrics ----\n",
    "        wce_per_sequence = np.max(np.abs(preds - H_gt), axis=1)\n",
    "        mse_per_sequence = np.mean((preds - H_gt) ** 2, axis=1)\n",
    "\n",
    "        mse = np.mean(mse_per_sequence)\n",
    "        wce = np.max(np.abs(preds - H_gt))\n",
    "        sre_per_sequence = np.sqrt(mse_per_sequence) / np.sqrt(np.mean(H_gt**2, axis=1))\n",
    "        sre_avg = np.mean(sre_per_sequence)\n",
    "        sre_95th = np.percentile(sre_per_sequence, 95)\n",
    "\n",
    "        dbdt_full = np.gradient(B_scenario, axis=1)\n",
    "        dbdt = dbdt_full[:, warm_up_len:]\n",
    "        nere_per_sequence = np.abs((((dbdt * preds) - (dbdt * H_gt)).sum(axis=1)) / np.abs(loss[msk_N])) #added abs\n",
    "        nere_avg = np.mean(nere_per_sequence)\n",
    "        nere_95th = np.percentile(nere_per_sequence, 95)\n",
    "\n",
    "        print(f\"\\tMSE : {mse:>7.2f} (A/m)²\")\n",
    "        print(f\"\\tWCE : {wce:>7.2f} A/m\")\n",
    "\n",
    "        metrics_d[scenario_labels[scenario_i]] = {\n",
    "            \"mse\": np.round(mse, 3).item(),\n",
    "            \"wce\": np.round(wce, 3).item(),\n",
    "            \"sre_avg\": np.round(sre_avg, 3).item(),\n",
    "            \"sre_95th\": np.round(sre_95th, 3).item(),\n",
    "            \"nere_avg\": np.round(nere_avg, 3).item(),\n",
    "            \"nere_95th\": np.round(nere_95th, 3).item(),\n",
    "        }\n",
    "\n",
    "        # optional plots\n",
    "        if show_plots:\n",
    "            n_plots = min(5, preds.shape[0])\n",
    "            idx_argmax = np.argpartition(wce_per_sequence, -n_plots)[-n_plots:]\n",
    "\n",
    "            fig, axes = plt.subplots(n_plots, 1, sharex=True, figsize=(10, 2.5 * n_plots))\n",
    "            if n_plots == 1:\n",
    "                axes = [axes]\n",
    "            for j, idx in enumerate(idx_argmax):\n",
    "                ax = axes[j]\n",
    "                ax.plot(H_gt[idx], label=\"gt\")\n",
    "                ax.plot(preds[idx], label=\"pred\", ls=\"dashed\")\n",
    "                ax.annotate(\n",
    "                    f\"MSE {mse_per_sequence[idx]:.1f} (A/m)² | WCE {wce_per_sequence[idx]:.1f} A/m\",\n",
    "                    (0.3, 0.1), xycoords=ax.transAxes\n",
    "                )\n",
    "                ax.grid(alpha=0.3)\n",
    "                ax.set_ylabel(\"H in A/m\")\n",
    "            axes[0].set_title(f\"Worst-case predictions - {scenario_labels[scenario_i]}\")\n",
    "            axes[-1].set_xlabel(\"Sequence step\")\n",
    "            axes[0].legend()\n",
    "            fig.tight_layout()\n",
    "\n",
    "    return metrics_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f786660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_model_ja_gru = evaluate_pretest_scenarios_custom(wrappend_model_ja_gru,B, T, H_init, H_true, loss, msks_scenarios_N_tup,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7129016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_model_ja = evaluate_pretest_scenarios_custom(wrappend_model_ja,B, T, H_init, H_true, loss, msks_scenarios_N_tup,False)\n",
    "# metrics_model_ja2 = evaluate_pretest_scenarios_custom(wrappend_model_ja2,B, T, H_init, H_true, loss, msks_scenarios_N_tup,False)\n",
    "metrics_model_ja_gru = evaluate_pretest_scenarios_custom(wrappend_model_ja_gru,B, T, H_init, H_true, loss, msks_scenarios_N_tup,False)\n",
    "metrics_model_gru = evaluate_pretest_scenarios_custom(wrappend_model_gru,B, T, H_init, H_true, loss, msks_scenarios_N_tup,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9c5e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosts_d = {\"3C90\": {scenario_labels[0]: {\"mse\": None, \"wce\": None, \"sre_avg\": 0.1305, \"sre_95th\": 0.347, \"nere_avg\": 0.007623, \"nere_95th\": 0.01928}, # 90 % known\n",
    "           scenario_labels[1]: {\"mse\": None, \"wce\": None, \"sre_avg\": 0.1602, \"sre_95th\": 0.3443, \"nere_avg\": 0.0341, \"nere_95th\": 0.05603}, # 50 % known\n",
    "           scenario_labels[2]: {\"mse\": None, \"wce\": None, \"sre_avg\": 0.1704, \"sre_95th\": 0.3476, \"nere_avg\": 0.0618, \"nere_95th\": 0.07476}}, # 10 % known\n",
    "           \"N87\": {scenario_labels[0]: {\"mse\": None, \"wce\": None, \"sre_avg\": 0.1962, \"sre_95th\": 0.521, \"nere_avg\": 0.007805, \"nere_95th\": 0.0157}, # 90 % known\n",
    "           scenario_labels[1]: {\"mse\": None, \"wce\": None, \"sre_avg\": 0.2767, \"sre_95th\": 0.8498, \"nere_avg\": 0.02577, \"nere_95th\": 0.05509}, # 50 % known\n",
    "           scenario_labels[2]: {\"mse\": None, \"wce\": None, \"sre_avg\": 0.3028, \"sre_95th\": 0.9999, \"nere_avg\": 0.04828, \"nere_95th\": 0.0681} # 10 % known\n",
    "           }}\n",
    "all_models_d = {\"hosts\": hosts_d[mat], \"GRU\": metrics_model_gru, \"JA\": metrics_model_ja,\"JAGRUlin\": metrics_model_ja_gru } #,\"JA2\": metrics_model_ja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94574b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3C90\n",
    "df_models_3C90 = create_multilevel_df(all_models_d)\n",
    "display(HTML(df_models_3C90.T.to_html(float_format=\"%.3f\", bold_rows=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8554d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_mc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
