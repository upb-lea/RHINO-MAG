{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75944817",
   "metadata": {},
   "source": [
    "# PINN\n",
    "\n",
    "PINN for the Jiles-Atherton model with GRUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4ab373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\"\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "\n",
    "# jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import equinox as eqx\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4210b2c8-a440-4557-af45-ef8653fc2eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mc2.utils.data_inspection import (\n",
    "    get_available_material_names,\n",
    "    get_file_overview,\n",
    "    filter_file_overview,\n",
    "    load_single_file,\n",
    "    load_and_process_single_from_full_file_overview,\n",
    ")\n",
    "from mc2.utils.data_plotting import plot_single_sequence\n",
    "from mc2.data_management import FrequencySet, MaterialSet, DataSet, NormalizedFrequencySet, load_data_into_pandas_df\n",
    "from mc2.features.features_jax import add_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c410ad0c-4d9e-46d1-8f3e-3399aa842dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mc2.training.jax_routine import train_model\n",
    "from mc2.models.model_interface import ModelInterface, RNNwInterface\n",
    "from mc2.models.RNN import GRU\n",
    "\n",
    "from mc2.features.features_jax import compute_fe_single\n",
    "def featurize(norm_B_past, norm_H_past, norm_B_future, temperature):\n",
    "    past_length = norm_B_past.shape[0]\n",
    "    future_length = norm_B_future.shape[0]\n",
    "\n",
    "    featurized_B = compute_fe_single(jnp.hstack([norm_B_past, norm_B_future]), n_s=10)\n",
    "\n",
    "    return featurized_B[past_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2a1956e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data for 3C90: 100%|██████████| 21/21 [00:06<00:00,  3.13it/s]\n",
      "INFO:2025-11-10 09:27:38,444:jax._src.xla_bridge:925: Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-10 09:27:38 | INFO : Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2025-11-10 09:27:38,446:jax._src.xla_bridge:925: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-10 09:27:38 | INFO : Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "data_dict = load_data_into_pandas_df(material=\"3C90\")\n",
    "mat_set = MaterialSet.from_pandas_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24803a48-2bfd-4ffe-bbc6-753da494202c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match shape of indexed array in index 0: got (3300,), expected (2978,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m dataset_3C90 = mat_set\n\u001b[32m      6\u001b[39m mat_set_f = dataset_3C90.at_frequency(\u001b[32m500_000\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m mat_set_f_T_25 = \u001b[43mmat_set_f\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter_temperatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemperatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m mat_set_f_T_50 = mat_set_f.filter_temperatures(temperatures=[\u001b[32m50\u001b[39m])\n\u001b[32m      9\u001b[39m mat_set_f_T_70 = mat_set_f.filter_temperatures(temperatures=[\u001b[32m70\u001b[39m])\n",
      "    \u001b[31m[... skipping hidden 1 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/magnet-challenge-2/mc2/data_management.py:153\u001b[39m, in \u001b[36mFrequencySet.filter_temperatures\u001b[39m\u001b[34m(self, temperatures)\u001b[39m\n\u001b[32m    147\u001b[39m     temperatures = jnp.array(temperatures)\n\u001b[32m    149\u001b[39m temperature_mask = jnp.isin(\u001b[38;5;28mself\u001b[39m.T, temperatures)\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m FrequencySet(\n\u001b[32m    151\u001b[39m     material_name=\u001b[38;5;28mself\u001b[39m.material_name,\n\u001b[32m    152\u001b[39m     frequency=\u001b[38;5;28mself\u001b[39m.frequency,\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     H=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mH\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtemperature_mask\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[32m    154\u001b[39m     B=\u001b[38;5;28mself\u001b[39m.B[temperature_mask],\n\u001b[32m    155\u001b[39m     T=\u001b[38;5;28mself\u001b[39m.T[temperature_mask],\n\u001b[32m    156\u001b[39m     H_RMS=\u001b[38;5;28mself\u001b[39m.H_RMS[temperature_mask],\n\u001b[32m    157\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/mc2/lib/python3.11/site-packages/jax/_src/array.py:382\u001b[39m, in \u001b[36mArrayImpl.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    377\u001b[39m       out = lax.squeeze(out, dimensions=dims)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayImpl(\n\u001b[32m    380\u001b[39m         out.aval, sharding, [out], committed=\u001b[38;5;28;01mFalse\u001b[39;00m, _skip_checks=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrewriting_take\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/mc2/lib/python3.11/site-packages/jax/_src/numpy/indexing.py:632\u001b[39m, in \u001b[36mrewriting_take\u001b[39m\u001b[34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value, out_sharding)\u001b[39m\n\u001b[32m    626\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(aval, core.DShapedArray) \u001b[38;5;129;01mand\u001b[39;00m aval.shape == () \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    627\u001b[39m         dtypes.issubdtype(aval.dtype, np.integer) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    628\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m dtypes.issubdtype(aval.dtype, dtypes.bool_) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    629\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(arr.shape[\u001b[32m0\u001b[39m], \u001b[38;5;28mint\u001b[39m)):\n\u001b[32m    630\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m lax.dynamic_index_in_dim(arr, idx, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m treedef, static_idx, dynamic_idx = \u001b[43msplit_index_for_jit\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[32m    634\u001b[39m                unique_indices, mode, fill_value, out_sharding)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/mc2/lib/python3.11/site-packages/jax/_src/numpy/indexing.py:724\u001b[39m, in \u001b[36msplit_index_for_jit\u001b[39m\u001b[34m(idx, shape)\u001b[39m\n\u001b[32m    720\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mJAX does not support string indexing; got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    722\u001b[39m \u001b[38;5;66;03m# Expand any (concrete) boolean indices. We can then use advanced integer\u001b[39;00m\n\u001b[32m    723\u001b[39m \u001b[38;5;66;03m# indexing logic to handle them.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m idx = \u001b[43m_expand_bool_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    726\u001b[39m leaves, treedef = tree_flatten(idx)\n\u001b[32m    727\u001b[39m dynamic = [\u001b[38;5;28;01mNone\u001b[39;00m] * \u001b[38;5;28mlen\u001b[39m(leaves)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/mc2/lib/python3.11/site-packages/jax/_src/numpy/indexing.py:1056\u001b[39m, in \u001b[36m_expand_bool_indices\u001b[39m\u001b[34m(idx, shape)\u001b[39m\n\u001b[32m   1053\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtoo many boolean indices at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: got mask of shape \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1054\u001b[39m                        \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, but only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(expected_shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m dimensions remain.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1055\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(s1 \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m0\u001b[39m, s2) \u001b[38;5;28;01mfor\u001b[39;00m s1, s2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(i_shape, expected_shape)):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mboolean index did not match shape of indexed array in index \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1057\u001b[39m                        \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1058\u001b[39m     out.extend(np.where(i))\n\u001b[32m   1059\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mIndexError\u001b[39m: boolean index did not match shape of indexed array in index 0: got (3300,), expected (2978,)"
     ]
    }
   ],
   "source": [
    "# new for data sampling and batch\n",
    "# dataset_3C90 = DataSet.load_from_file(pathlib.Path(\"../../../data/processed\") / \"3C90.pickle\")\n",
    "\n",
    "dataset_3C90 = mat_set\n",
    "\n",
    "mat_set_f = dataset_3C90.at_frequency(500_000)\n",
    "mat_set_f_T_25 = mat_set_f.filter_temperatures(temperatures=[25])\n",
    "mat_set_f_T_50 = mat_set_f.filter_temperatures(temperatures=[50])\n",
    "mat_set_f_T_70 = mat_set_f.filter_temperatures(temperatures=[70])\n",
    "train_set_f_T_25, val_set_f_T_25, test_set_f_T_25 = mat_set_f_T_25.split_into_train_val_test(\n",
    "    train_frac=0.7, val_frac=0.15, test_frac=0.15, seed=12\n",
    ")\n",
    "train_set_f_T_50, val_set_f_T_50, test_set_f_T_50 = mat_set_f_T_50.split_into_train_val_test(\n",
    "    train_frac=0.7, val_frac=0.15, test_frac=0.15, seed=12\n",
    ")\n",
    "train_set_f_T_70, val_set_f_T_70, test_set_f_T_70 = mat_set_f_T_70.split_into_train_val_test(\n",
    "    train_frac=0.7, val_frac=0.15, test_frac=0.15, seed=12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf478b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ddb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU\n",
    "\n",
    "class MyModel(eqx.Module):\n",
    "    net: eqx.Module\n",
    "    Ms: jnp.ndarray  # skalare Größen, die wir lernen wollen\n",
    "    a: jnp.ndarray\n",
    "    alpha: jnp.ndarray\n",
    "    c: jnp.ndarray\n",
    "    k: jnp.ndarray\n",
    "    # out_layer: eqx.Module\n",
    "    \n",
    "    def __init__(self,input_size,hidden_size,*,key):\n",
    "        init_key, key = jr.split(key)\n",
    "        self.net = eqx.nn.GRUCell(\n",
    "            input_size = input_size,\n",
    "            hidden_size = hidden_size,\n",
    "            key = init_key\n",
    "        )\n",
    "        \n",
    "        key1, key2, key3, key4, key5, key6 = jr.split(key,6)\n",
    "        Ms_key = jr.uniform(key1)\n",
    "        a_key = jr.uniform(key2)\n",
    "        a_key = jr.uniform(key3)\n",
    "        alpha_key = jr.uniform(key4)\n",
    "        c_key = jr.uniform(key5)\n",
    "        k_key = jr.uniform(key6) \n",
    "        \n",
    "        self.Ms = jnp.array([1.6e6], dtype=jnp.float32)\n",
    "        self.a=jnp.array([110], dtype=jnp.float32)\n",
    "        self.alpha = jnp.array([1.6e-3], dtype=jnp.float32)\n",
    "        self.c=jnp.array([0.2], dtype=jnp.float32)\n",
    "        self.k = jnp.array([400.01], dtype=jnp.float32)\n",
    "        # self.out_layer = eqx.nn.Linear(in_features=1,out_features=1,key=init_key)\n",
    " \n",
    "    def __call__(self, inp):\n",
    "        hidden = jnp.zeros(self.net.hidden_size)\n",
    "\n",
    "        def scan_fn(carry, inp):\n",
    "            gru_out = self.net(inp,carry)\n",
    "            gru_out_o = jnp.atleast_2d(gru_out)\n",
    "            out = gru_out_o[:,0]\n",
    "            return gru_out, out\n",
    "\n",
    "        _, out = jax.lax.scan(scan_fn, hidden, inp)\n",
    "        # out_o = self.out_layer(out)\n",
    "        return out\n",
    "    \n",
    "# Reproducibility\n",
    "key = jr.PRNGKey(0)\n",
    "\n",
    "# Our PINN is a coordinate network in the form of a LSTM, mapping from scalar to scalar values\n",
    "key, init_key = jr.split(key)\n",
    "\n",
    "hidden_size=2\n",
    "model = MyModel(input_size=1,hidden_size=hidden_size,key=init_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d786659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H_e, after (4)\n",
    "def He_fn(model,H,M):\n",
    "    return  H + model.alpha*M\n",
    "\n",
    "# Man (6)\n",
    "def Man_fn(model,H,M):\n",
    "    return model.Ms*(jnp.tanh(He_fn(model,H,M)/model.a)-(model.a/He_fn(model,H,M)))\n",
    "\n",
    "\n",
    "# delta\n",
    "def delta_fn(H):\n",
    "    H_new = jnp.squeeze(H)\n",
    "    diff_H = jnp.diff(H_new,append=1)\n",
    "    delta = jnp.sign(diff_H)\n",
    "    \n",
    "    return delta\n",
    "\n",
    "#  eq (19)\n",
    "def fn_dM_dH(model,H,M):\n",
    "    numerator = Man_fn(model,H,M) - M\n",
    "    numerator = jnp.squeeze(numerator)\n",
    "        \n",
    "    part1 = delta_fn(H)*model.k/mu_0\n",
    "    part2 = model.alpha*(Man_fn(model,H,M)-M)\n",
    "    part2_sqee = jnp.squeeze(part2)\n",
    "\n",
    "    print(f\"part1: {part1.shape}\")\n",
    "    print(f\"part2: {part2.shape}\")\n",
    "    print(f\"part2_sqee: {part2_sqee.shape}\")\n",
    "    print(f\"numerator: {numerator.shape}\")\n",
    "    \n",
    "    # denominator = delta_fn(H)*model.k/mu_0 - model.alpha*(Man_fn(model,H,M)-M)\n",
    "    denominator = (delta_fn(H)*model.k)/mu_0 - part2_sqee\n",
    "\n",
    "    M_rev =  model.c*(Man_fn(model,H,M)-M)\n",
    "    M_rev = jnp.squeeze(M_rev)\n",
    "\n",
    "    # (19) + (31)\n",
    "    dM_dH = numerator/denominator + M_rev\n",
    "    return dM_dH\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a201e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def physics(model,H,B,B_next):\n",
    "    dB_dt_est = (B_next - B) / TAU\n",
    "    dB_dt_est = jnp.squeeze(dB_dt_est)\n",
    "    M = B / mu_0 - H\n",
    "    dM_dH = fn_dM_dH(model,H,M)\n",
    "    dM_dB = dM_dH / (mu_0 * (1 + dM_dH))\n",
    "\n",
    "    print(f\"dM_dB {dM_dB.shape}\")\n",
    "    print(f\"dB_dt_est: {dB_dt_est.shape}\")\n",
    "    \n",
    "    dM_dt = dM_dB * dB_dt_est\n",
    "    dH_dt = 1/mu_0 * dB_dt_est - dM_dt\n",
    "\n",
    "    return dH_dt\n",
    "\n",
    "def residuum(model,B):\n",
    "    return model(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e599e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "\n",
    "def loss_fn(model,H,B,B_next):\n",
    "    physics_at_collocation_points = jax.vmap(physics, in_axes=(None,None,0,None))(model, H, B, B_next)\n",
    "    \n",
    "    physics_loss_contribution = 0.5*jnp.mean(jnp.square(physics_at_collocation_points))\n",
    "\n",
    "    prediction = jax.vmap(residuum,in_axes=(None,0))(model,B)\n",
    "    prediction_loss_contribution = 0.5*jnp.mean(jnp.square(prediction-H))\n",
    "\n",
    "    total_loss = 1e-20*physics_loss_contribution + prediction_loss_contribution\n",
    "    # total_loss = prediction_loss_contribution\n",
    "\n",
    "    return total_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88e192a-9bf6-4d11-9176-a434a779fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_3C90 = DataSet.load_from_file(pathlib.Path(\"../../../data/processed\") / \"3C90.pickle\")\n",
    "relevant_data = dataset_3C90.at_frequency(500_000).filter_temperatures([25])\n",
    "\n",
    "# H = relevant_data.H[:10,0:1000][...,None]\n",
    "# B = relevant_data.B[:10,0:1000][...,None]\n",
    "# B_next = relevant_data.B[:10,1:1001][...,None]\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "N_OPTIMIZATION_EPOCHS = 1_000\n",
    "mu_0 = 4*jnp.pi*10**(-7)\n",
    "TAU = 1/16e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e645b176-6e43-4445-85c1-6711954c4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_norm = train_set_f_T_25.normalize(transform_H=True, featurize=featurize) #, feature_names=feature_names\n",
    "# train_set_norm = train_set_f_T_50.normalize(transform_H=True, featurize=featurize) #, feature_names=feature_names\n",
    "# train_set_norm = train_set_f_T_70.normalize(transform_H=True, featurize=featurize) #, feature_names=feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1353bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "optimizer = optax.adam(LEARNING_RATE)\n",
    "opt_state = optimizer.init(eqx.filter(model, eqx.is_array))\n",
    "\n",
    "@eqx.filter_jit\n",
    "def make_step(model,H,B,opt_state,B_next):\n",
    "    loss, grad = eqx.filter_value_and_grad(loss_fn)(model,H,B,B_next)\n",
    "    updates, new_state = optimizer.update(grad, opt_state, model)\n",
    "    new_model = eqx.apply_updates(model, updates)\n",
    "    B_next = B_next\n",
    "\n",
    "    return new_model, new_state, loss\n",
    "\n",
    "loss_history = []\n",
    "Ms_history = []\n",
    "a_history = []\n",
    "alpha_history = []\n",
    "c_history = []\n",
    "k_history = []\n",
    "\n",
    "N_TEMP = 3\n",
    "sequ = 1\n",
    "temp = 1\n",
    "\n",
    "for temp in range(N_TEMP):\n",
    "    if temp == 0:\n",
    "        train_set_norm = train_set_f_T_25.normalize(transform_H=True, featurize=featurize) #, feature_names=feature_names\n",
    "    if temp == 2:\n",
    "        train_set_norm = train_set_f_T_50.normalize(transform_H=True, featurize=featurize) #, feature_names=feature_names\n",
    "    if temp == 3:\n",
    "        train_set_norm = train_set_f_T_70.normalize(transform_H=True, featurize=featurize) #, feature_names=feature_names\n",
    "\n",
    "\n",
    "    H = train_set_norm.H[1:3,:][...,None]\n",
    "    B = train_set_norm.B[1:3,:][...,None]\n",
    "    B_next = jnp.roll(B,1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for epoch in range(N_OPTIMIZATION_EPOCHS):\n",
    "        model, opt_state, loss = make_step(model,H,B,opt_state,B_next)\n",
    "        loss_history.append(loss)\n",
    "        Ms_history.append(model.Ms)\n",
    "        a_history.append(model.a)\n",
    "        alpha_history.append(model.alpha)\n",
    "        c_history.append(model.c)\n",
    "        k_history.append(model.k)\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch: {epoch}, loss: {loss}, Ms:{model.Ms}, a:{model.a}, alpha:{model.alpha}, c:{model.c}, k:{model.k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b232ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d08c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ii in range(10):\n",
    "#     plt.plot(H[ii], label=\"data\", color=\"gray\",alpha=0.6)\n",
    "#     # plt.plot(H[ii], jax.vmap(model)(H)[ii], label=\"Final PINN solution\")\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6588d0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(10):\n",
    "    plt.plot(H[ii], label=\"data\", color=\"gray\",alpha=0.6)\n",
    "    plt.plot(jax.vmap(model)(B)[ii], label=\"Final PINN solution\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92b2a20-ad19-4182-882c-72170c5087c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
