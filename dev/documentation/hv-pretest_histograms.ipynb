{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe7b1b6-a79f-4803-b859-b52dd41bd4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5f67c7-f429-4d20-abb1-4ab50203d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\"\n",
    "\n",
    "import pathlib\n",
    "import glob\n",
    "import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc1985d-9e32-4700-a066-92e4bd640243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'serif','serif':['Helvetica']})\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams.update({'font.size': 10})\n",
    "mpl.rcParams['text.latex.preamble']=r\"\\usepackage{bm}\\usepackage{amsmath}\\usepackage{upgreek}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d13914-b83d-45e1-b30c-e035ccbe40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "import equinox as eqx\n",
    "\n",
    "from mc2.utils.model_evaluation import reconstruct_model_from_exp_id\n",
    "from mc2.model_interfaces.model_interface import count_model_parameters\n",
    "from mc2.utils.pretest_evaluation import produce_pretest_histograms, SCENARIO_LABELS, DETAILED_SCENARIO_LABELS, store_pretest_results_to_csv, load_hdf5_pretest_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c675c74-e0d1-483a-b15a-edb4acda3e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_ids = [\n",
    "    '3C90_GRU_97c4047f-c2d8-48',\n",
    "    'N87_GRU_8ba07f4f-c59a-42',\n",
    "    '3C94_GRU_b7cf990c-33b5-49',\n",
    "    '3E6_GRU_e45054a0-3df2-4c',\n",
    "    '3F4_GRU_6d364e15-88db-46',\n",
    "    '77_GRU_db53aa04-5f27-43',\n",
    "    '78_GRU_69379b64-4b79-42',\n",
    "    'N27_GRU_41070eb0-0850-4f',\n",
    "    'N30_GRU_9eca1a85-eaec-4a',\n",
    "    'N49_GRU_9d34af17-f5bc-46',\n",
    "]\n",
    "wrapped_models = {exp_id.split(\"_\")[0]: reconstruct_model_from_exp_id(exp_id) for exp_id in exp_ids}\n",
    "\n",
    "print(\"n_models:\", len(wrapped_models.values()))\n",
    "for model in wrapped_models.values():\n",
    "    print(\"parameters_per_model:\", model.n_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134632b5-147b-4621-bcd3-bd8b08c91e6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for exp_id, (material_name, wrapped_model) in zip(exp_ids, wrapped_models.items()):\n",
    "    seed = 0\n",
    "\n",
    "    assert exp_id.split(\"_\")[0] == material_name\n",
    "\n",
    "    # wrapped_model = reconstruct_model_from_exp_id(exp_id)\n",
    "    print(\"Number of parameters:\", wrapped_model.n_params)\n",
    "    \n",
    "    B, T, H_init, H_true, loss, loss_short, msks_scenarios_N_tup = load_hdf5_pretest_data(material_name)\n",
    "    \n",
    "    fig, axs = produce_pretest_histograms(\n",
    "        material_name,\n",
    "        wrapped_model,\n",
    "        B,\n",
    "        T,\n",
    "        H_init,\n",
    "        H_true,\n",
    "        loss,\n",
    "        msks_scenarios_N_tup,\n",
    "        scenario_labels=SCENARIO_LABELS,\n",
    "        adapted_scenario_labels=DETAILED_SCENARIO_LABELS,\n",
    "        show_plots=False,\n",
    "    );\n",
    "    plt.savefig(f\"histograms/{exp_id}_preevaluation_results.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    store_pretest_results_to_csv(\n",
    "        pathlib.Path(\"csvs/\"),\n",
    "        exp_id,\n",
    "        wrapped_model,\n",
    "        B,\n",
    "        T,\n",
    "        H_init,\n",
    "        H_true,\n",
    "        loss,\n",
    "        msks_scenarios_N_tup,\n",
    "        scenario_labels=SCENARIO_LABELS,\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282e11a5-d171-460e-bb22-ec37b55e57a4",
   "metadata": {},
   "source": [
    "## Assert proper form of the csvs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d74bd-d64c-4a85-894e-a0ecf17cbaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "from mc2.metrics import sre, nere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2fb7b0-a8b6-429a-8ec8-ecad781686b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp_id in exp_ids:\n",
    "    predictions = pd.read_csv(f\"csvs/{exp_id}_pred.csv\", header=None)\n",
    "\n",
    "    material_name = exp_id.split(\"_\")[0]\n",
    "    print(material_name)\n",
    "\n",
    "    if material_name == \"N49\":\n",
    "        # display(predictions)\n",
    "        predictions = jnp.array(predictions)\n",
    "        assert predictions.shape == (4500, 1000)\n",
    "    \n",
    "        B, T, H_init, H_true, loss, loss_short, msks_scenarios_N_tup = load_hdf5_pretest_data(material_name)\n",
    "        \n",
    "        assert jnp.all(predictions[:1500, :100] == H_init[:1500, :100])\n",
    "        assert jnp.all(predictions[1500:3000, :500] == H_init[1500:3000, :500])\n",
    "        assert jnp.all(predictions[3000:, :900] == H_init[3000:, :900])\n",
    "    \n",
    "        # reproduce metric values:\n",
    "    \n",
    "        print(\"90% unknown\")\n",
    "    \n",
    "        preds = predictions[:1500, 100:]\n",
    "        H_gt = H_true[:1500, 100:]\n",
    "        B_scenario = B[:1500, :]\n",
    "        warm_up_len = 100\n",
    "        true_core_loss = jnp.squeeze(loss[:1500])\n",
    "        \n",
    "        wce_per_sequence = np.max(np.abs(preds - H_gt), axis=1)\n",
    "        mse_per_sequence = np.mean((preds - H_gt) ** 2, axis=1)\n",
    "        sre_per_sequence = eqx.filter_vmap(sre)(preds, H_gt)\n",
    "    \n",
    "        dbdt_full = np.gradient(B_scenario, axis=1)\n",
    "        dbdt = dbdt_full[:, warm_up_len:]\n",
    "        nere_per_sequence = eqx.filter_vmap(nere)(preds, H_gt, dbdt, np.abs(true_core_loss))\n",
    "        sre_avg = np.mean(sre_per_sequence)\n",
    "        sre_95th = np.percentile(sre_per_sequence, 95)\n",
    "    \n",
    "        nere_avg = np.mean(nere_per_sequence)\n",
    "        nere_95th = np.percentile(nere_per_sequence, 95)\n",
    "    \n",
    "        print(\"sre_avg:\", sre_avg)\n",
    "        print(\"sre_95th:\", sre_95th)\n",
    "        print(\"nere_avg:\", nere_avg)\n",
    "        print(\"nere_95th:\", nere_95th)\n",
    "    \n",
    "        print(\"50% unknown\")\n",
    "    \n",
    "        preds = predictions[1500:3000, 500:]\n",
    "        H_gt = H_true[1500:3000, 500:]\n",
    "        B_scenario = B[1500:3000, :]\n",
    "        warm_up_len = 500\n",
    "        true_core_loss = jnp.squeeze(loss[1500:3000])\n",
    "        \n",
    "        wce_per_sequence = np.max(np.abs(preds - H_gt), axis=1)\n",
    "        mse_per_sequence = np.mean((preds - H_gt) ** 2, axis=1)\n",
    "        sre_per_sequence = eqx.filter_vmap(sre)(preds, H_gt)\n",
    "    \n",
    "        dbdt_full = np.gradient(B_scenario, axis=1)\n",
    "        dbdt = dbdt_full[:, warm_up_len:]\n",
    "        nere_per_sequence = eqx.filter_vmap(nere)(preds, H_gt, dbdt, np.abs(true_core_loss))\n",
    "        sre_avg = np.mean(sre_per_sequence)\n",
    "        sre_95th = np.percentile(sre_per_sequence, 95)\n",
    "    \n",
    "        nere_avg = np.mean(nere_per_sequence)\n",
    "        nere_95th = np.percentile(nere_per_sequence, 95)\n",
    "    \n",
    "        print(\"sre_avg:\", sre_avg)\n",
    "        print(\"sre_95th:\", sre_95th)\n",
    "        print(\"nere_avg:\", nere_avg)\n",
    "        print(\"nere_95th:\", nere_95th)\n",
    "    \n",
    "        print(\"10% unknown\")\n",
    "    \n",
    "        preds = predictions[3000:, 900:]\n",
    "        H_gt = H_true[3000:, 900:]\n",
    "        B_scenario = B[3000:, :]\n",
    "        warm_up_len = 900\n",
    "        true_core_loss = jnp.squeeze(loss[3000:])\n",
    "        \n",
    "        wce_per_sequence = np.max(np.abs(preds - H_gt), axis=1)\n",
    "        mse_per_sequence = np.mean((preds - H_gt) ** 2, axis=1)\n",
    "        sre_per_sequence = eqx.filter_vmap(sre)(preds, H_gt)\n",
    "    \n",
    "        dbdt_full = np.gradient(B_scenario, axis=1)\n",
    "        dbdt = dbdt_full[:, warm_up_len:]\n",
    "        nere_per_sequence = eqx.filter_vmap(nere)(preds, H_gt, dbdt, np.abs(true_core_loss))\n",
    "        sre_avg = np.mean(sre_per_sequence)\n",
    "        sre_95th = np.percentile(sre_per_sequence, 95)\n",
    "    \n",
    "        nere_avg = np.mean(nere_per_sequence)\n",
    "        nere_95th = np.percentile(nere_per_sequence, 95)\n",
    "    \n",
    "        print(\"sre_avg:\", sre_avg)\n",
    "        print(\"sre_95th:\", sre_95th)\n",
    "        print(\"nere_avg:\", nere_avg)\n",
    "        print(\"nere_95th:\", nere_95th)\n",
    "    else:\n",
    "        # display(predictions)\n",
    "        predictions = jnp.array(predictions)\n",
    "        assert predictions.shape == (6300, 1000)\n",
    "    \n",
    "        B, T, H_init, H_true, loss, loss_short, msks_scenarios_N_tup = load_hdf5_pretest_data(material_name)\n",
    "        \n",
    "        assert jnp.all(predictions[:2100, :100] == H_init[:2100, :100])\n",
    "        assert jnp.all(predictions[2100:4200, :500] == H_init[2100:4200, :500])\n",
    "        assert jnp.all(predictions[4200:, :900] == H_init[4200:, :900])\n",
    "    \n",
    "        # reproduce metric values:\n",
    "    \n",
    "        print(\"90% unknown\")\n",
    "    \n",
    "        preds = predictions[:2100, 100:]\n",
    "        H_gt = H_true[:2100, 100:]\n",
    "        B_scenario = B[:2100, :]\n",
    "        warm_up_len = 100\n",
    "        true_core_loss = jnp.squeeze(loss[:2100])\n",
    "        \n",
    "        wce_per_sequence = np.max(np.abs(preds - H_gt), axis=1)\n",
    "        mse_per_sequence = np.mean((preds - H_gt) ** 2, axis=1)\n",
    "        sre_per_sequence = eqx.filter_vmap(sre)(preds, H_gt)\n",
    "    \n",
    "        dbdt_full = np.gradient(B_scenario, axis=1)\n",
    "        dbdt = dbdt_full[:, warm_up_len:]\n",
    "        nere_per_sequence = eqx.filter_vmap(nere)(preds, H_gt, dbdt, np.abs(true_core_loss))\n",
    "        sre_avg = np.mean(sre_per_sequence)\n",
    "        sre_95th = np.percentile(sre_per_sequence, 95)\n",
    "    \n",
    "        nere_avg = np.mean(nere_per_sequence)\n",
    "        nere_95th = np.percentile(nere_per_sequence, 95)\n",
    "    \n",
    "        print(\"sre_avg:\", sre_avg)\n",
    "        print(\"sre_95th:\", sre_95th)\n",
    "        print(\"nere_avg:\", nere_avg)\n",
    "        print(\"nere_95th:\", nere_95th)\n",
    "    \n",
    "        print(\"50% unknown\")\n",
    "    \n",
    "        preds = predictions[2100:4200, 500:]\n",
    "        H_gt = H_true[2100:4200, 500:]\n",
    "        B_scenario = B[2100:4200, :]\n",
    "        warm_up_len = 500\n",
    "        true_core_loss = jnp.squeeze(loss[2100:4200])\n",
    "        \n",
    "        wce_per_sequence = np.max(np.abs(preds - H_gt), axis=1)\n",
    "        mse_per_sequence = np.mean((preds - H_gt) ** 2, axis=1)\n",
    "        sre_per_sequence = eqx.filter_vmap(sre)(preds, H_gt)\n",
    "    \n",
    "        dbdt_full = np.gradient(B_scenario, axis=1)\n",
    "        dbdt = dbdt_full[:, warm_up_len:]\n",
    "        nere_per_sequence = eqx.filter_vmap(nere)(preds, H_gt, dbdt, np.abs(true_core_loss))\n",
    "        sre_avg = np.mean(sre_per_sequence)\n",
    "        sre_95th = np.percentile(sre_per_sequence, 95)\n",
    "    \n",
    "        nere_avg = np.mean(nere_per_sequence)\n",
    "        nere_95th = np.percentile(nere_per_sequence, 95)\n",
    "    \n",
    "        print(\"sre_avg:\", sre_avg)\n",
    "        print(\"sre_95th:\", sre_95th)\n",
    "        print(\"nere_avg:\", nere_avg)\n",
    "        print(\"nere_95th:\", nere_95th)\n",
    "    \n",
    "        print(\"10% unknown\")\n",
    "    \n",
    "        preds = predictions[4200:, 900:]\n",
    "        H_gt = H_true[4200:, 900:]\n",
    "        B_scenario = B[4200:, :]\n",
    "        warm_up_len = 900\n",
    "        true_core_loss = jnp.squeeze(loss[4200:])\n",
    "        \n",
    "        wce_per_sequence = np.max(np.abs(preds - H_gt), axis=1)\n",
    "        mse_per_sequence = np.mean((preds - H_gt) ** 2, axis=1)\n",
    "        sre_per_sequence = eqx.filter_vmap(sre)(preds, H_gt)\n",
    "    \n",
    "        dbdt_full = np.gradient(B_scenario, axis=1)\n",
    "        dbdt = dbdt_full[:, warm_up_len:]\n",
    "        nere_per_sequence = eqx.filter_vmap(nere)(preds, H_gt, dbdt, np.abs(true_core_loss))\n",
    "        sre_avg = np.mean(sre_per_sequence)\n",
    "        sre_95th = np.percentile(sre_per_sequence, 95)\n",
    "    \n",
    "        nere_avg = np.mean(nere_per_sequence)\n",
    "        nere_95th = np.percentile(nere_per_sequence, 95)\n",
    "    \n",
    "        print(\"sre_avg:\", sre_avg)\n",
    "        print(\"sre_95th:\", sre_95th)\n",
    "        print(\"nere_avg:\", nere_avg)\n",
    "        print(\"nere_95th:\", nere_95th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e53fda-825c-4390-8efd-8806d8e30759",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = pd.read_csv(f\"csvs/{exp_ids[0]}_pred.csv\", header=None)\n",
    "print(exp_id[0])\n",
    "display(predictions)\n",
    "predictions = jnp.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461989e-304b-457d-be34-1ed2c1177302",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENARIO_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba12cce1-6c89-4c16-9408-b70a0a135865",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, H_init, H_true, loss, loss_short, msks_scenarios_N_tup = load_hdf5_pretest_data(material_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a3abba-e8dc-4aa4-9e3b-64dfd65131a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbd5f4e-98b4-4be1-9431-0ce2d4e6e392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a2180e-e25e-4d9a-95e9-f0152d194aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be6c82-6a15-4b0f-82c4-13fe4c5fdf20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
